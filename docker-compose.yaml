name: spark-cluster
services:
  spark-master:
    image: bitnami/spark:3.5.0
    environment:
      - SPARK_MODE=master
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/opt/spark/spark-events
      - PYTHONPATH=/home/spark/work/src
    ports:
      - '8080:8080'
      - '7077:7077'
      - "18080:18080"
    volumes:
      - ./src:/home/spark/work/src
      - ./data/output:/home/spark/work/data/output
      - ./data/input:/home/spark/work/data/input
      - spark-events:/opt/spark/spark-events
    command: ["/bin/bash", "-c", "spark-class org.apache.spark.deploy.master.Master & spark-class org.apache.spark.deploy.history.HistoryServer"]

  spark-worker:
    image: bitnami/spark:3.5.0
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=${SPARK_WORKER_MEMORY}G
      - SPARK_WORKER_CORES=${SPARK_WORKER_CORES}
    volumes:
      - ./data/output:/home/spark/work/data/output
      - ./data/input:/home/spark/work/data/input

  jupyter:
    user: root
    image: jupyter/pyspark-notebook:latest
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - NB_USER=spark
      - NB_UID=1001
      - JUPYTER_ENABLE_LAB=yes
      - PYTHONPATH=/home/spark/work/src
    ports:
      - "8888:8888"
    volumes:
      - ./src:/home/spark/work/src
      - ./data/output:/home/spark/work/data/output
      - ./data/input:/home/spark/work/data/input
      - spark-events:/opt/spark/spark-events
    command: >
      /bin/bash -c "chown -R 1001:100 /home/spark &&
                    /usr/local/bin/start-notebook.sh --ServerApp.token='' --ServerApp.password='' --ServerApp.allow_origin='*'"
    depends_on:
      - spark-master
      - spark-worker
    deploy:
      replicas: ${WITH_JUPYTER:-0}

volumes:
  spark-events:
    external: true
